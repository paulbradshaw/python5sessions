{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas01basicsCompile.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eRVlOdiwWW"
      },
      "source": [
        "# Intro to `pandas`\n",
        "\n",
        "This notebook introduces basic techniques in using `pandas` for data analysis.\n",
        "\n",
        "First, we need to import the `pandas` library. This is pre-installed in Colab notebooks, so doesn't need installing - it only needs bringing in with the `import` command.\n",
        "\n",
        "It's also quite common to rename the library when it's imported, as `pd`, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4zRPsakisxl"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5_5MQUojE4z"
      },
      "source": [
        "The inverted pyramid of data journalism outlines 5 stages:\n",
        "\n",
        "1. Compile\n",
        "2. Clean\n",
        "3. Combine\n",
        "4. Context\n",
        "5. Clean\n",
        "\n",
        "And running throughout it: **question**.\n",
        "\n",
        "Let's start with compiling in `pandas`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fexF0GrDePs"
      },
      "source": [
        "## Compiling data: importing a CSV\n",
        "\n",
        "The easiest way to compile data in a Colab notebook is to upload the data to the Files area on the left hand side of Colab. Once in the Files view, it can be brought into the notebook with the `read_csv()` function.\n",
        "\n",
        "Colab already has a 'sample_data' folder in Files with 4 CSV files and a JSON file. We can export one of those to demonstrate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1qecTSjYK8",
        "outputId": "caaf91bd-0f0a-4f01-b893-bd4c8542abb3"
      },
      "source": [
        "#import the CSV from the Files in Colab\n",
        "caldata = pd.read_csv(\"sample_data/california_housing_test.csv\")\n",
        "#print the results\n",
        "print(caldata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      longitude  latitude  ...  median_income  median_house_value\n",
            "0       -122.05     37.37  ...         6.6085            344700.0\n",
            "1       -118.30     34.26  ...         3.5990            176500.0\n",
            "2       -117.81     33.78  ...         5.7934            270500.0\n",
            "3       -118.36     33.82  ...         6.1359            330000.0\n",
            "4       -119.67     36.33  ...         2.9375             81700.0\n",
            "...         ...       ...  ...            ...                 ...\n",
            "2995    -119.86     34.42  ...         1.1790            225000.0\n",
            "2996    -118.14     34.06  ...         3.3906            237200.0\n",
            "2997    -119.70     36.30  ...         2.2895             62000.0\n",
            "2998    -117.12     34.10  ...         3.2708            162500.0\n",
            "2999    -119.63     34.42  ...         8.5608            500001.0\n",
            "\n",
            "[3000 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrAreXx3yeSX"
      },
      "source": [
        "### Importing Excel files\n",
        "\n",
        "If your data is an Excel spreadsheet in .xlsx format you will need [pandas's `read_excel` function](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html).\n",
        "\n",
        "I've downloaded an Excel spreadsheet on [*Operation of police powers under the Terrorism Act 2000, financial year ending March 2021*](https://www.gov.uk/government/statistics/operation-of-police-powers-under-the-terrorism-act-2000-financial-year-ending-march-2021) and then uploaded it to the Files area in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NekEGcNTzAvl",
        "outputId": "0b95b4ef-5ae2-4009-8bd0-54172b129ca5"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\")\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Unnamed: 0                                         Unnamed: 1\n",
            "0          NaN                                                NaN\n",
            "1          NaN                                                NaN\n",
            "2          NaN                                                NaN\n",
            "3          NaN                                                NaN\n",
            "4          NaN                                                NaN\n",
            "5          NaN  Statistics on the operation of police powers u...\n",
            "6          NaN             Year to March 2021: Annual Data Tables\n",
            "7          NaN                                                NaN\n",
            "8          NaN                                                NaN\n",
            "9          NaN                                                NaN\n",
            "10         NaN                                                NaN\n",
            "11         NaN                                                NaN\n",
            "12         NaN              Responsible Statistician: Daniel Shaw\n",
            "13         NaN       Enquiries: CTAI_Statistics@homeoffice.gov.uk\n",
            "14         NaN                            Published: 10 June 2021\n",
            "15         NaN                             Crown copyright Â© 2021\n",
            "16         NaN                                                NaN\n",
            "17         NaN                                           Contents\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBKGdfawzUnd"
      },
      "source": [
        "Note that the spreadsheet has a bunch of `NaN` cells and unnamed columns. It's also imported the first sheet by default. \n",
        "\n",
        "You can control these by adding extra parameters to the `read_excel()` function like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3lUEoJc-ofw",
        "outputId": "71420e60-63fd-450e-b2a4-61d763a29c14"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\", sheet_name = 3, skiprows = 5)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Period of detention Charged  ... Other.20 Total.20\n",
            "0                                                 NaN     NaN  ...      NaN      NaN\n",
            "1                                         Under 1 day       4  ...     63.0    757.0\n",
            "2                               1 to less than 2 days       3  ...     26.0    367.0\n",
            "3                               2 to less than 3 days       1  ...      1.0     57.0\n",
            "4                               3 to less than 4 days       9  ...     16.0    131.0\n",
            "5                               4 to less than 5 days       9  ...      9.0    115.0\n",
            "6                               5 to less than 6 days       1  ...      6.0    139.0\n",
            "7                               6 to less than 7 days       7  ...      8.0    260.0\n",
            "8                               7 to less than 8 days       0  ...      5.0     24.0\n",
            "9                               8 to less than 9 days       0  ...      1.0     24.0\n",
            "10                             9 to less than 10 days       0  ...      2.0     35.0\n",
            "11                            10 to less than 11 days       0  ...      0.0     21.0\n",
            "12                            11 to less than 12 days       0  ...      0.0     40.0\n",
            "13                            12 to less than 13 days       0  ...      3.0     34.0\n",
            "14                            13 to less than 14 days       0  ...      7.0     76.0\n",
            "15                            14 to less than 15 days       *  ...      0.0      1.0\n",
            "16                            15 to less than 16 days       *  ...      0.0      0.0\n",
            "17                            16 to less than 17 days       *  ...      0.0      0.0\n",
            "18                            17 to less than 18 days       *  ...      0.0      0.0\n",
            "19                            18 to less than 19 days       *  ...      0.0      1.0\n",
            "20                            19 to less than 20 days       *  ...      0.0      3.0\n",
            "21                            20 to less than 21 days       *  ...      0.0      0.0\n",
            "22                            21 to less than 22 days       *  ...      0.0      0.0\n",
            "23                            22 to less than 23 days       *  ...      0.0      0.0\n",
            "24                            23 to less than 24 days       *  ...      0.0      0.0\n",
            "25                            24 to less than 25 days       *  ...      0.0      0.0\n",
            "26                            25 to less than 26 days       *  ...      0.0      0.0\n",
            "27                            26 to less than 27 days       *  ...      0.0      0.0\n",
            "28                            27 to less than 28 days       *  ...      0.0      6.0\n",
            "29                                              Total      34  ...    147.0   2091.0\n",
            "30  Source: National Counter-Terrorism Police Oper...     NaN  ...      NaN      NaN\n",
            "31                                                NaN     NaN  ...      NaN      NaN\n",
            "32                                        ' - ' = Nil     NaN  ...      NaN      NaN\n",
            "33                             ' * ' = Not applicable     NaN  ...      NaN      NaN\n",
            "34  1.  Includes all detentions following an arres...     NaN  ...      NaN      NaN\n",
            "35  2.  The 'other' category includes cautions for...     NaN  ...      NaN      NaN\n",
            "36  3.  Data presented here are based on the lates...     NaN  ...      NaN      NaN\n",
            "37  4.  Totals since 11 September 2001 include tho...     NaN  ...      NaN      NaN\n",
            "38  5.  Figures for the year ending March 2002 inc...     NaN  ...      NaN      NaN\n",
            "\n",
            "[39 rows x 105 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdR1EHnE_Ney"
      },
      "source": [
        "Note that: \n",
        "\n",
        "* The first ingredient (argument) for `pd.read_excel(` is a string with the name of the spreadsheet, including .xlsx.\n",
        "* The second argument is `sheet_name =` which is set to `3` meaning the fourth sheet (counting begins at 0 in Python)\n",
        "* And the `skiprows =` argument is set to `5`, meaning that it will skip 5 rows and use row 6 for column headings.\n",
        "\n",
        "Other arguments are [listed in the documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html). Key ones to note are:\n",
        "\n",
        "* `header = ` - which row to use for column headings\n",
        "* `usecols = ` - which columns to keep. This can be column letter ranges as strings, e.g. `\"A:E\" or \"A,C,E:F\"`, or integers as a list, e.g. `[1:10]`\n",
        "* `nrows = ` - the number of rows to import. For example you might only want to import the first 100 rows to begin with in a large dataset, or all the rows before any footnotes\n",
        "* `skipfooter = ` is a similar argument which allows you to skip the last few rows by specifying how many rows at the end you want to leave out\n",
        "* `parse_dates = ` - specify which columns you want to import as dates, e.g. `[2,3]`. Check the documentation for more information on how to combine columns (e.g. day, month, year) as a date\n",
        "\n",
        "Here's an example of using more of those with our spreadsheet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggb_JEBZBomY",
        "outputId": "d739c8ca-54e2-4214-af8c-c74cc401b16b"
      },
      "source": [
        "#store the url first so you can see all the arguments below\n",
        "theurlwewant = \"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\"\n",
        "#read that url and specify a sheet name, header row and footers to skip\n",
        "terrdata = pd.read_excel(theurlwewant, sheet_name = 3, header = 5, skipfooter=9)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Period of detention Charged Released  ... Released.20 Other.20  Total.20\n",
            "0                       NaN     NaN      NaN  ...         NaN      NaN       NaN\n",
            "1               Under 1 day       4       22  ...       556.0     63.0     757.0\n",
            "2     1 to less than 2 days       3       13  ...       257.0     26.0     367.0\n",
            "3     2 to less than 3 days       1        0  ...        30.0      1.0      57.0\n",
            "4     3 to less than 4 days       9        9  ...        56.0     16.0     131.0\n",
            "5     4 to less than 5 days       9        3  ...        55.0      9.0     115.0\n",
            "6     5 to less than 6 days       1        0  ...        52.0      6.0     139.0\n",
            "7     6 to less than 7 days       7        4  ...        78.0      8.0     260.0\n",
            "8     7 to less than 8 days       0        0  ...         8.0      5.0      24.0\n",
            "9     8 to less than 9 days       0        0  ...         7.0      1.0      24.0\n",
            "10   9 to less than 10 days       0        0  ...         9.0      2.0      35.0\n",
            "11  10 to less than 11 days       0        0  ...        11.0      0.0      21.0\n",
            "12  11 to less than 12 days       0        0  ...        12.0      0.0      40.0\n",
            "13  12 to less than 13 days       0        0  ...         8.0      3.0      34.0\n",
            "14  13 to less than 14 days       0        0  ...        14.0      7.0      76.0\n",
            "15  14 to less than 15 days       *        *  ...         0.0      0.0       1.0\n",
            "16  15 to less than 16 days       *        *  ...         0.0      0.0       0.0\n",
            "17  16 to less than 17 days       *        *  ...         0.0      0.0       0.0\n",
            "18  17 to less than 18 days       *        *  ...         0.0      0.0       0.0\n",
            "19  18 to less than 19 days       *        *  ...         0.0      0.0       1.0\n",
            "20  19 to less than 20 days       *        *  ...         0.0      0.0       3.0\n",
            "21  20 to less than 21 days       *        *  ...         0.0      0.0       0.0\n",
            "22  21 to less than 22 days       *        *  ...         0.0      0.0       0.0\n",
            "23  22 to less than 23 days       *        *  ...         0.0      0.0       0.0\n",
            "24  23 to less than 24 days       *        *  ...         0.0      0.0       0.0\n",
            "25  24 to less than 25 days       *        *  ...         0.0      0.0       0.0\n",
            "26  25 to less than 26 days       *        *  ...         0.0      0.0       0.0\n",
            "27  26 to less than 27 days       *        *  ...         0.0      0.0       0.0\n",
            "28  27 to less than 28 days       *        *  ...         3.0      0.0       6.0\n",
            "29                    Total      34       51  ...      1156.0    147.0    2091.0\n",
            "\n",
            "[30 rows x 105 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_WNvecqCJ8F",
        "outputId": "3a9e1e02-d084-4fce-b3a1-4c099a570b18"
      },
      "source": [
        "terrdata = pd.read_excel(\"operation-police-powers-terrorism-mar2021-annual-tables.xlsx\", sheet_name = 3, header = 5)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Period of detention Charged  ... Other.20 Total.20\n",
            "0                                                 NaN     NaN  ...      NaN      NaN\n",
            "1                                         Under 1 day       4  ...     63.0    757.0\n",
            "2                               1 to less than 2 days       3  ...     26.0    367.0\n",
            "3                               2 to less than 3 days       1  ...      1.0     57.0\n",
            "4                               3 to less than 4 days       9  ...     16.0    131.0\n",
            "5                               4 to less than 5 days       9  ...      9.0    115.0\n",
            "6                               5 to less than 6 days       1  ...      6.0    139.0\n",
            "7                               6 to less than 7 days       7  ...      8.0    260.0\n",
            "8                               7 to less than 8 days       0  ...      5.0     24.0\n",
            "9                               8 to less than 9 days       0  ...      1.0     24.0\n",
            "10                             9 to less than 10 days       0  ...      2.0     35.0\n",
            "11                            10 to less than 11 days       0  ...      0.0     21.0\n",
            "12                            11 to less than 12 days       0  ...      0.0     40.0\n",
            "13                            12 to less than 13 days       0  ...      3.0     34.0\n",
            "14                            13 to less than 14 days       0  ...      7.0     76.0\n",
            "15                            14 to less than 15 days       *  ...      0.0      1.0\n",
            "16                            15 to less than 16 days       *  ...      0.0      0.0\n",
            "17                            16 to less than 17 days       *  ...      0.0      0.0\n",
            "18                            17 to less than 18 days       *  ...      0.0      0.0\n",
            "19                            18 to less than 19 days       *  ...      0.0      1.0\n",
            "20                            19 to less than 20 days       *  ...      0.0      3.0\n",
            "21                            20 to less than 21 days       *  ...      0.0      0.0\n",
            "22                            21 to less than 22 days       *  ...      0.0      0.0\n",
            "23                            22 to less than 23 days       *  ...      0.0      0.0\n",
            "24                            23 to less than 24 days       *  ...      0.0      0.0\n",
            "25                            24 to less than 25 days       *  ...      0.0      0.0\n",
            "26                            25 to less than 26 days       *  ...      0.0      0.0\n",
            "27                            26 to less than 27 days       *  ...      0.0      0.0\n",
            "28                            27 to less than 28 days       *  ...      0.0      6.0\n",
            "29                                              Total      34  ...    147.0   2091.0\n",
            "30  Source: National Counter-Terrorism Police Oper...     NaN  ...      NaN      NaN\n",
            "31                                                NaN     NaN  ...      NaN      NaN\n",
            "32                                        ' - ' = Nil     NaN  ...      NaN      NaN\n",
            "33                             ' * ' = Not applicable     NaN  ...      NaN      NaN\n",
            "34  1.  Includes all detentions following an arres...     NaN  ...      NaN      NaN\n",
            "35  2.  The 'other' category includes cautions for...     NaN  ...      NaN      NaN\n",
            "36  3.  Data presented here are based on the lates...     NaN  ...      NaN      NaN\n",
            "37  4.  Totals since 11 September 2001 include tho...     NaN  ...      NaN      NaN\n",
            "38  5.  Figures for the year ending March 2002 inc...     NaN  ...      NaN      NaN\n",
            "\n",
            "[39 rows x 105 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrhMqJKDqg_"
      },
      "source": [
        "### Importing JSON\n",
        "\n",
        "Data in the JSON format can be imported using `read_json`. Below we import another piece of data in Colab's 'sample_data' folder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02r-VRM-S-ZQ",
        "outputId": "86dfb3f8-6030-48cd-951e-165c7f8b70dd"
      },
      "source": [
        "anscombe = pd.read_json(\"sample_data/anscombe.json\")\n",
        "print(anscombe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Series   X      Y\n",
            "0       I  10   8.04\n",
            "1       I   8   6.95\n",
            "2       I  13   7.58\n",
            "3       I   9   8.81\n",
            "4       I  11   8.33\n",
            "5       I  14   9.96\n",
            "6       I   6   7.24\n",
            "7       I   4   4.26\n",
            "8       I  12  10.84\n",
            "9       I   7   4.81\n",
            "10      I   5   5.68\n",
            "11     II  10   9.14\n",
            "12     II   8   8.14\n",
            "13     II  13   8.74\n",
            "14     II   9   8.77\n",
            "15     II  11   9.26\n",
            "16     II  14   8.10\n",
            "17     II   6   6.13\n",
            "18     II   4   3.10\n",
            "19     II  12   9.13\n",
            "20     II   7   7.26\n",
            "21     II   5   4.74\n",
            "22    III  10   7.46\n",
            "23    III   8   6.77\n",
            "24    III  13  12.74\n",
            "25    III   9   7.11\n",
            "26    III  11   7.81\n",
            "27    III  14   8.84\n",
            "28    III   6   6.08\n",
            "29    III   4   5.39\n",
            "30    III  12   8.15\n",
            "31    III   7   6.42\n",
            "32    III   5   5.73\n",
            "33     IV   8   6.58\n",
            "34     IV   8   5.76\n",
            "35     IV   8   7.71\n",
            "36     IV   8   8.84\n",
            "37     IV   8   8.47\n",
            "38     IV   8   7.04\n",
            "39     IV   8   5.25\n",
            "40     IV  19  12.50\n",
            "41     IV   8   5.56\n",
            "42     IV   8   7.91\n",
            "43     IV   8   6.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65rCbFiFXP2g"
      },
      "source": [
        "### Importing from an online source\n",
        "\n",
        "The same functions can also be used to import data an online source - you just need to use the URL of the file. \n",
        "\n",
        "Below we import CSV [from a GitHub repo](https://github.com/BBC-Data-Unit/stalking_protection_orders). GitHub displays CSVs nicely as tables - but note that in order to get the link to the actual CSV *data* you need to click on the CSV link in GitHub and *then* click on **Raw**. The URL should start `raw.githubusercontent.com`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pRrGZbrXIFS",
        "outputId": "63e3d35d-424c-4a5f-ee79-a616bac774ef"
      },
      "source": [
        "stalkingdata = pd.read_csv(\"https://raw.githubusercontent.com/BBC-Data-Unit/stalking_protection_orders/main/forsharing_stalking_protection_orders%20-%20Main_dataset.csv\")\n",
        "print(stalkingdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Police force  ... charge_rate_apr20_dec20\n",
            "0      Avon and Somerset   ...                      4%\n",
            "1           Bedfordshire   ...                      4%\n",
            "2         Cambridgeshire   ...                      9%\n",
            "3               Cheshire   ...                      6%\n",
            "4              Cleveland   ...                      8%\n",
            "5                Cumbria   ...                      9%\n",
            "6             Derbyshire   ...                      6%\n",
            "7       Devon & Cornwall   ...                      8%\n",
            "8                 Dorset   ...                      7%\n",
            "9                 Durham   ...                      6%\n",
            "10            Dyfed Powys  ...                      7%\n",
            "11                 Essex   ...                      8%\n",
            "12       Gloucestershire   ...                     11%\n",
            "13    Greater Manchester   ...                 #DIV/0!\n",
            "14                  Gwent  ...                     11%\n",
            "15             Hampshire   ...                      6%\n",
            "16         Hertfordshire   ...                      8%\n",
            "17            Humberside   ...                      7%\n",
            "18                  Kent   ...                      2%\n",
            "19            Lancashire   ...                      5%\n",
            "20        Leicestershire   ...                      3%\n",
            "21          Lincolnshire   ...                      5%\n",
            "22            Merseyside   ...                     17%\n",
            "23  Metropolitan  Service  ...                      2%\n",
            "24               Norfolk   ...                      6%\n",
            "25            North Wales  ...                      5%\n",
            "26       North Yorkshire   ...                   #REF!\n",
            "27      Northamptonshire   ...                      5%\n",
            "28           Northumbria   ...                      6%\n",
            "29       Nottinghamshire   ...                     37%\n",
            "30            South Wales  ...                      3%\n",
            "31       South Yorkshire   ...                      3%\n",
            "32         Staffordshire   ...                      3%\n",
            "33               Suffolk   ...                     18%\n",
            "34                Surrey   ...                     23%\n",
            "35                Sussex   ...                      4%\n",
            "36         Thames Valley   ...                      7%\n",
            "37          Warwickshire   ...                     16%\n",
            "38           West Mercia   ...                      7%\n",
            "39         West Midlands   ...                      1%\n",
            "40        West Yorkshire   ...                      0%\n",
            "41             Wiltshire   ...                      0%\n",
            "\n",
            "[42 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWoDp2dbXtO6"
      },
      "source": [
        "The same process can be used to import Excel spreadsheets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGd_nw0Xlfg",
        "outputId": "15208cdd-7014-46fb-cc53-b5eae4e0b97b"
      },
      "source": [
        "terrdata = pd.read_excel(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/991988/operation-police-powers-terrorism-mar2021-annual-tables.xlsx\", sheet_name=3, header=5)\n",
        "print(terrdata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Period of detention Charged  ... Other.20 Total.20\n",
            "0                                                 NaN     NaN  ...      NaN      NaN\n",
            "1                                         Under 1 day       4  ...     63.0    757.0\n",
            "2                               1 to less than 2 days       3  ...     26.0    367.0\n",
            "3                               2 to less than 3 days       1  ...      1.0     57.0\n",
            "4                               3 to less than 4 days       9  ...     16.0    131.0\n",
            "5                               4 to less than 5 days       9  ...      9.0    115.0\n",
            "6                               5 to less than 6 days       1  ...      6.0    139.0\n",
            "7                               6 to less than 7 days       7  ...      8.0    260.0\n",
            "8                               7 to less than 8 days       0  ...      5.0     24.0\n",
            "9                               8 to less than 9 days       0  ...      1.0     24.0\n",
            "10                             9 to less than 10 days       0  ...      2.0     35.0\n",
            "11                            10 to less than 11 days       0  ...      0.0     21.0\n",
            "12                            11 to less than 12 days       0  ...      0.0     40.0\n",
            "13                            12 to less than 13 days       0  ...      3.0     34.0\n",
            "14                            13 to less than 14 days       0  ...      7.0     76.0\n",
            "15                            14 to less than 15 days       *  ...      0.0      1.0\n",
            "16                            15 to less than 16 days       *  ...      0.0      0.0\n",
            "17                            16 to less than 17 days       *  ...      0.0      0.0\n",
            "18                            17 to less than 18 days       *  ...      0.0      0.0\n",
            "19                            18 to less than 19 days       *  ...      0.0      1.0\n",
            "20                            19 to less than 20 days       *  ...      0.0      3.0\n",
            "21                            20 to less than 21 days       *  ...      0.0      0.0\n",
            "22                            21 to less than 22 days       *  ...      0.0      0.0\n",
            "23                            22 to less than 23 days       *  ...      0.0      0.0\n",
            "24                            23 to less than 24 days       *  ...      0.0      0.0\n",
            "25                            24 to less than 25 days       *  ...      0.0      0.0\n",
            "26                            25 to less than 26 days       *  ...      0.0      0.0\n",
            "27                            26 to less than 27 days       *  ...      0.0      0.0\n",
            "28                            27 to less than 28 days       *  ...      0.0      6.0\n",
            "29                                              Total      34  ...    147.0   2091.0\n",
            "30  Source: National Counter-Terrorism Police Oper...     NaN  ...      NaN      NaN\n",
            "31                                                NaN     NaN  ...      NaN      NaN\n",
            "32                                        ' - ' = Nil     NaN  ...      NaN      NaN\n",
            "33                             ' * ' = Not applicable     NaN  ...      NaN      NaN\n",
            "34  1.  Includes all detentions following an arres...     NaN  ...      NaN      NaN\n",
            "35  2.  The 'other' category includes cautions for...     NaN  ...      NaN      NaN\n",
            "36  3.  Data presented here are based on the lates...     NaN  ...      NaN      NaN\n",
            "37  4.  Totals since 11 September 2001 include tho...     NaN  ...      NaN      NaN\n",
            "38  5.  Figures for the year ending March 2002 inc...     NaN  ...      NaN      NaN\n",
            "\n",
            "[39 rows x 105 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTe7ANH54Z6m"
      },
      "source": [
        "## Importing all sheets within an Excel file\n",
        "\n",
        "You can also read an entire Excel file first in order to see what sheets it contains and select more than one sheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGqegahR4rY2",
        "outputId": "577a7f7f-9603-4d4d-cf61-32e87bf382f9"
      },
      "source": [
        "#read in an Excel file\n",
        "xlfile = pd.ExcelFile(\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/991988/operation-police-powers-terrorism-mar2021-annual-tables.xlsx\")\n",
        "#what are the sheet names?\n",
        "print(xlfile.sheet_names)\n",
        "#how many sheets\n",
        "print(len(xlfile.sheet_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Front Page', 'A - Index', 'A - A.01', 'A - A.02', 'A - A.03', 'A - A.04', 'A - A.05a', 'A - A.05b', 'A - A.05c', 'A - A.06a', 'A - A.06b', 'A - A.06c', 'A - A.07', 'A - A.08a', 'A - A.08b', 'A - A.08c', 'A - A.09', 'A - A.10', 'A - A.11', 'A - A.12a', 'A - A.12b', 'A - A.12c', 'A C.01', 'A C.02', 'A C.03', 'A C.04', 'A C.05', 'A P.01', 'A P.02', 'A P.03', 'A P.04', 'A P.05', 'A P.06', 'A S.01', 'A S.02', 'A S.03', 'A S.04']\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rAQNIc6Fbm"
      },
      "source": [
        "If sheets contain the same data (e.g. a different sheet for each region, but the same columns) then this approach can be used to merge them, by looping through each sheet name you want to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsOTsPaqfJJd"
      },
      "source": [
        "## Importing from GitHub\n",
        "\n",
        "We can import some data from GitHub using the 'Raw' link on [the data file page](https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls) - but we get an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "3qITLiVcdWI3",
        "outputId": "efd2af0a-feb0-408e-a2e9-47c4c5534946"
      },
      "source": [
        "githublink = \"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls?raw=true\"\n",
        "disposals = pd.ExcelFile(githublink)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XLRDError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0e829e9997d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reqd: 0x%04x\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrqd_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'\\n\\n\\n\\n\\n\\n<!'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzcvUSYGfYV1"
      },
      "source": [
        "Some googling finds a [solution](https://stackoverflow.com/questions/66648775/how-to-get-link-of-xlsx-file-in-github-to-be-opened-as-a-pandas-dataframe) involving a couple other libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ILhcgddvFU",
        "outputId": "a6fdae79-3f02-4600-a0c5-b28d92328b00"
      },
      "source": [
        "#https://stackoverflow.com/questions/66648775/how-to-get-link-of-xlsx-file-in-github-to-be-opened-as-a-pandas-dataframe\n",
        "import requests as rq\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://github.com/paulbradshaw/cleaning/blob/master/dirtydata/Disposals%20by%20region%202012-13%20Table.xls?raw=true\"\n",
        "data = rq.get(url).content\n",
        "disposals = pd.ExcelFile(BytesIO(data))\n",
        "\n",
        "#what are the sheet names?\n",
        "print(disposals.sheet_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['National', 'East Midlands', 'Eastern', 'London', 'North East', 'North West', 'South East', 'South West', 'Wales', 'West Midlands', 'Yorkshire']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFGQTT5efsYO"
      },
      "source": [
        "## Looping through sheets to import them and combine\n",
        "\n",
        "This particular spreadsheet has a different sheet for each area. Here's how we might combine them all into one dataframe:\n",
        "\n",
        "First, we use `read_excel()` with that variable containing the Excel spreadsheet, and specify the first sheet (index 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "BeaSfqv2mhAv",
        "outputId": "5544bbdb-0a4e-464a-bdc2-dbf7f54e7d21"
      },
      "source": [
        "#import the first sheet\n",
        "dis1 = pd.read_excel(disposals, sheet_name=0, skiprows=1)\n",
        "dis1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>These figures do not match the data published in Chapter 5 as they are taken from a different data source.</th>\n",
              "      <th>10 - 14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17+</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Not Known</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>White</th>\n",
              "      <th>Mixed</th>\n",
              "      <th>Asian or Asian British</th>\n",
              "      <th>Black or Black British</th>\n",
              "      <th>Chinese or Other Ethnic Group</th>\n",
              "      <th>Not Known.1</th>\n",
              "      <th>TOTAL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>National</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pre-court</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reprimand</td>\n",
              "      <td>4726.0</td>\n",
              "      <td>2795.0</td>\n",
              "      <td>2814.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3524.0</td>\n",
              "      <td>9530.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11302.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>458.0</td>\n",
              "      <td>498.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>13055.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Final Warning</td>\n",
              "      <td>3467.0</td>\n",
              "      <td>2404.0</td>\n",
              "      <td>2491.0</td>\n",
              "      <td>2587.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2350.0</td>\n",
              "      <td>8596.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9562.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>10949.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  These figures do not match the data published in Chapter 5 as they are taken from a different data source.  ...    TOTAL\n",
              "0                                           National                                                          ...      NaN\n",
              "1                                                NaN                                                          ...      NaN\n",
              "2                                         Pre-court                                                           ...      NaN\n",
              "3                                          Reprimand                                                          ...  13055.0\n",
              "4                                      Final Warning                                                          ...  10949.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1CmQp9BoUSI"
      },
      "source": [
        "Then we loop through the list of sheet names and use those to do the same for every other sheet - appending it to the dataframe containing the data from sheet 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzlNURkrmZMj",
        "outputId": "20d2480b-821f-4c1f-9534-d469e45a7176"
      },
      "source": [
        "#create a dataframe that's a copy of sheet index 0\n",
        "disposalsall = dis1\n",
        "#add a column for the sheet it came from\n",
        "disposalsall['sheet'] = \"National\"\n",
        "\n",
        "#loop through the sheet names from index 1 onwards\n",
        "for i in disposals.sheet_names[1:]:\n",
        "  print(i)\n",
        "  #grab the sheet at that position\n",
        "  currentsheet = pd.read_excel(disposals, sheet_name=i, skiprows=1)\n",
        "  #add a column for the sheet it came from\n",
        "  currentsheet['sheet'] = i\n",
        "  #add to the ongoing dataframe\n",
        "  disposalsall = disposalsall.append(dis1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "East Midlands\n",
            "Eastern\n",
            "London\n",
            "North East\n",
            "North West\n",
            "South East\n",
            "South West\n",
            "Wales\n",
            "West Midlands\n",
            "Yorkshire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIjuTDEfnxLZ",
        "outputId": "d66a22c6-fa1a-4c23-8d89-6eb5438126eb"
      },
      "source": [
        "#show how many rows and cols the one-sheet dataframe has\n",
        "print(dis1.shape)\n",
        "#and the combined dataframe\n",
        "print(disposalsall.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(352, 18)\n",
            "(3872, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MyYoLkRoc9X"
      },
      "source": [
        "An alternative approach would be to measure the *length* of the sheet list and use that to generate indices for `sheet_name=` instead of the actual sheet name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC8jdZ98o81m",
        "outputId": "a8edbc0d-1dff-448b-aef4-ba723aae2632"
      },
      "source": [
        "disposalsall.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "These figures do not match the data published in Chapter 5 as they are taken from a different data source.     object\n",
              "10 - 14                                                                                                       float64\n",
              "15                                                                                                            float64\n",
              "16                                                                                                            float64\n",
              "17+                                                                                                           float64\n",
              "Unnamed: 5                                                                                                    float64\n",
              "Female                                                                                                        float64\n",
              "Male                                                                                                          float64\n",
              "Not Known                                                                                                     float64\n",
              "Unnamed: 9                                                                                                    float64\n",
              "White                                                                                                         float64\n",
              "Mixed                                                                                                         float64\n",
              "Asian or Asian British                                                                                        float64\n",
              "Black or Black British                                                                                        float64\n",
              "Chinese or Other Ethnic Group                                                                                 float64\n",
              "Not Known.1                                                                                                   float64\n",
              "TOTAL                                                                                                         float64\n",
              "sheet                                                                                                          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5geK_86TzyL"
      },
      "source": [
        "More functions for importing data are detailed on pandas's [documentation on import/export](https://pandas.pydata.org/docs/reference/io.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqRunamXVMXt"
      },
      "source": [
        "## Exporting data\n",
        "\n",
        "The same group of import/export functions can also be used to export data once you've finished doing analysis. These include\n",
        "\n",
        "* `.to_csv()`\n",
        "* `.to_excel()`\n",
        "* `.to_json()`\n",
        "* `.to_html()`\n",
        "* `.to_xml()`\n",
        "\n",
        "To use these, you need to put the name of a data frame *before* the period, and the name you want to give to the exported file as a **string** inside the parentheses. Like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80moRoneV2wo"
      },
      "source": [
        "anscombe.to_csv(\"anscombe.csv\")\n",
        "anscombe.to_excel(\"anscombe.xlsx\")\n",
        "anscombe.to_json(\"anscombe.json\")\n",
        "anscombe.to_html(\"anscombe.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITAaDp6NWESw"
      },
      "source": [
        "Once you run any of those commands you should see the resulting exported file in the Files view on the left in Colab. You can then download that file by hovering over it, clicking the three dots to the right, and selecting *Download*."
      ]
    }
  ]
}